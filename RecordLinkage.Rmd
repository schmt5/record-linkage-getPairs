---
title: "getPairs-Funktion im RecordLinkage-Package"
author: "Omar Besic, Thierry Schmidt, Chantal Zbinden"
date: "5/25/2019"
output:
  html_document:
    theme: united
    highlight: tango  
    toc: true
    toc_float:
      collapsed: false
---
<span style="color:blue">
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(RecordLinkage, quietly = TRUE)
```

### RecordLinkage package
Provides functions for linking and de-duplicating data sets. <br>
Methods based on a stochastic approach are implemented as well as classification algorithms <br>
from the machine learning domain.

###Data analysis
dataframe of 500 persons <br>
with firstname, second firstname, lastname, second lastname, birthyear, birthmonth and birthday

```{r dataframe}
data(RLdata500)
head(RLdata500)
```

###Building pairs on RLdata500 dataset
using compare.dedup to generate record pairs for deduplication or linkage. <br>
The summary shows 124'750 combinations based on the 500 datasets. <br>
There are no matching statuses because weight was not setted at this moment.

```{r generate Pairs Summary}
summary(compare.dedup(RLdata500))
```

blockfld aliviates the problem of n*(n-1)/2 and compares at least one of the field of 1,3,5,6,7 <br>
(compare columns 1, 3 or, 5 up to 7 for two records to  qualify to become a pair) <br>
with help of levenshteinSim formula we can compare the strings.
```{r comparededup}
rec.pairs <- compare.dedup(RLdata500
                           ,blockfld = list(1, 3, 5:7)
                           ,strcmp = c(2,3,4)
                           ,strcmpfun = levenshteinSim)
```

rec.pairs is list and there is dataframe of name pairs which is created in compare.dedup <br>
assign dataframe rec.pairs$pairs to matches 
```{r assign}
matches <- rec.pairs$pairs
```

give me the matches of all rows on which the restriction had be defined in blockfld for 1 = same | 0  = not same
```{r matches}

head(matches)


```

###Example 1 of pairs generated
show pair in row 2 (id1: 1, id2: 64)
show patient in row 1
show patient in row 64
```{r example1}
matches[2,]
RLdata500[1,]
RLdata500[64,]
```

###Example 2 of pairs generated
show pair in row 13 (id1: 2, id2: 43)
show patient in row 2
show patient in row 43
```{r example2}
matches[13,]
RLdata500[2,]
RLdata500[43,]
```


```{r compare}
#?compare.dedup()
rec.pairs <- compare.dedup(RLdata500,blockfld = list(1, 3, 5:7),strcmp = c(2,3,4),strcmpfun = levenshteinSim)
summary(rec.pairs)
```

### Vorgehen 2: Add weight calculation
<p><span style="color:blue"><b>1. Variante mit epiWeight:</b>"Calculates weights for record paris based on the EpiLink approach"</span></p>
Werte von 0 bis 1

<p><span style="color:blue"><b>2. Variante mit emWeight:</b>"Calculates weights for Record Linkage based on an EM algorithm"</span></p>
Werte von -10 bis 35

#### epiWeight in example
```{r weight}
rec.pairs <- epiWeights(rec.pairs)
length(rec.pairs$pairs$id1) #Anzahl Pairs
length(rec.pairs$Wdata) #Anzahl Weights
head(rec.pairs$Wdata) #Overview of data rparis - weights
```
For each pair a weight has been calculated

#### Histogramm of epiWeight
```{r histo}
hist(rec.pairs$Wdata)
```

### Vorgehen 3: getPairs

<li>show paris with the weights of them</li>
<li>use filter on weights</li>

```{r getPairs}
head(getPairs(rec.pairs, min.weight=0.5, max.weight=0.6)) #show all record pairs with weights between 0.5 and 0.6
tail(getPairs(rec.pairs, min.weight=0.5, max.weight=0.6))
rpairs <- getPairs(rec.pairs, single.rows=FALSE) #generate pairs of data.frame rec.pairs
length(rpairs$id) #not number of pairs, if single.row = FALSE, because 1 pairs use 3 rows

```

### Vorgehen 4: Classification
"To select with "show" in getPairs() function, you need first to Classify your dataset with epiClassify() or emClassify() depending your approach (epiWeight or emWeight)"

<li><span style="color:blue"><strong>emClassify: </strong>Classifies data pairs to which weights were assigned by <b>emWeights</b>. Based on user-defined threholds or predefined error rates</span></li>
<p><span style="color:blue">Two general approaches are implemented. The classical procedure by Fellegi and Sunter minimizes the number of possible links with given error levels for false links (my) and false non-links (ny).</span></p>
<p><span style="color:blue">The second approach requires threholds for links and possible links to be set by the user. A pair with weight w is classified as a link if w >= threshold.upper, as a possible link if threhold.upper >= w >= threshold.lower and as a non-link if w < threshold.lower.</span></p>
<p><span style="color:blue">If threshold.upper or threshold.lower is given, the threshold-based approach is used, otherwise, if one of the error bounds is given, the Fellegi-Sunter model. If only my is supplied, links are chosen to meet the error bound and all other pairs are classified as non-links (the equivalent case holds if only ny is specified). If no further arguments than rpairs are given, a single threshold of 0 is used.</span></p>
<p><span style="color:blue">The quality of classification of the Fellegi-Sunter method relies strongly on resonable estimations of m- and u-probabilities. The results should be evaluated critically.</span></p>

<li><span style="color:blue"><strong>epClassify: </strong></span></li>

Neue Variablen: prediction und threshold

<li>Threshold.upper --> Schwellenwet ab wann Pairs zu links werden</li>
<li>Threshold.under --> Schwellenwert ab wann non-links zu possible links werden</li>

Possible prediction-levels: non-linked and linked (no possible's because only threshold.upper defined)

If no threshold.under is defined; treshold.under = treshold.upper 
</span>
```{r classify}
cldata <- epiClassify(rec.pairs, 0.5) #threshold.lower = threshold.upper if not defined
summary(cldata$prediction)
cldata <- epiClassify(rec.pairs, 0.6, 0.4)
summary(cldata$prediction)
head(getPairs(cldata, show="links", single.rows=FALSE)) #now we can filter, show="links", "nonlinks", "possible" or "all"
```

###False matches and false non-matches
Now we can check which of the pairs are false-negative and which are false-positive. 
In other words, which of these pairs form synonyms (false-negative) or homonyms (false-positive)?

Therefore we use the RLBigDataDedup method, add weights with the epi aproach and weight them by 0.5 

```{r Synonym, warning=FALSE}
data(RLdata500)
testdata <- RLdata500
data <- RLBigDataDedup(testdata, identity = identity.RLdata500,
                       blockfld=list(1,3,5:7),
                       strcmp = c(2,3,4),
                       strcmpfun = "levenshtein")
data <- epiWeights(data)
result <- epiClassify(data, 0.5)
```

<li><span style="color:blue"><strong>Synonym: </strong></span></li>
Example: Martin and Maeddae: same person is meant, but the pair does not form a link.<br>
Give me all synonyms based on my weight of 0.5

```{r getFalseNeg}
 getFalseNeg(result)
```

<li><span style="color:blue"><strong>Homonym: </strong></span></li>
Example: Jan and Jan: not the same person, but the pair forms a link because string is the same.
```{r Homonym}
 getFalsePos(result)
```

### Fragestellung
<p><span style="color:red">"Dear Professor Sariyar: I am using your great tools to do matching. I got a quick question: In getPairs (matcher or links), we have filter.match = c("match", "unknown", "nonmatch"), filter.link = c("nonlink", "possible", "link"), do we have any ways to calculate theri confidence levels related? Thanks and best regards..."</span></p>

### Threshold determination

#### 1. Clerical Review

```{r threshold cl}

```
#### 2. getParetoThreshold
<p><span style="color:blue">Calculates a classification threshold based on a generalized Pareto distribution fitted to the weights distribution of the given data pairs</span></p>
```{r threshold parteo}

```
#### 3. optimalThreshold
<p><span style="color:blue">Calculates the optimal threshold for weight-based RecordLinkage</span></p> <ul><li><span style="color:blue">my = error bound for false positives</span></li><li><span style="color:blue">ny = error bound for false negatives</span></li>

```{r threshold optimal}

```

